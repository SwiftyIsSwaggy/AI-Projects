{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Training with TensorFlow in Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n",
      "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.8/site-packages/tensorflow/_api/v2/version/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import shutil\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sagemaker\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "urls = ['http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz',\n",
    "        'http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz']\n",
    "\n",
    "print('Libraries imported')\n",
    "\n",
    "print(tf.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract(data_dir, download_dir):\n",
    "    for url in urls:\n",
    "        target_file = url.split('/')[-1]\n",
    "        if target_file not in os.listdir(download_dir):\n",
    "            print('Downloading', url)\n",
    "            urllib.request.urlretrieve(url, os.path.join(download_dir, target_file))\n",
    "            tf = tarfile.open(url.split('/')[-1])\n",
    "            tf.extractall(data_dir)\n",
    "        else:\n",
    "            print('Already downloaded', url)\n",
    "\n",
    "def get_annotations(file_path, annotations={}):\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        rows = f.read().splitlines()\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        image_name, _, _, _ = row.split(' ')\n",
    "        class_name = image_name.split('_')[:-1]\n",
    "        class_name = '_'.join(class_name)\n",
    "        image_name = image_name + '.jpg'\n",
    "        \n",
    "        annotations[image_name] = 'cat' if class_name[0] != class_name[0].lower() else 'dog'\n",
    "    \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
      "Downloading http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "download_and_extract('data', '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples 7349\n"
     ]
    }
   ],
   "source": [
    "annotations = get_annotations('data/annotations/trainval.txt')\n",
    "annotations = get_annotations('data/annotations/test.txt', annotations)\n",
    "\n",
    "total_count = len(annotations.keys())\n",
    "print('Total examples', total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Abyssinian_100.jpg', 'cat')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(annotations.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['cat', 'dog']\n",
    "sets = ['train', 'validation']\n",
    "root_dir = 'custom_data'\n",
    "\n",
    "if not os.path.isdir(root_dir):\n",
    "    os.mkdir(root_dir)\n",
    "    \n",
    "for set_name in sets:\n",
    "    if not os.path.isdir(os.path.join(root_dir, set_name)):\n",
    "        os.mkdir(os.path.join(root_dir, set_name))\n",
    "    for class_name in classes:\n",
    "        folder = os.path.join(root_dir, set_name, class_name)\n",
    "        if not os.path.isdir(folder):\n",
    "            os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the files to correct set/ class folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, class_name in annotations.items():\n",
    "    target_set = 'validation' if random.randint(0, 99) < 20 else 'train'\n",
    "    target_path = os.path.join(root_dir, target_set, class_name, image)\n",
    "    shutil.copy(os.path.join('data/images/', image), target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_data/train/cat has 1890 images\n",
      "custom_data/train/dog has 3965 images\n",
      "custom_data/validation/cat has 481 images\n",
      "custom_data/validation/dog has 1013 images\n",
      "{'train': 5855, 'validation': 1494}\n"
     ]
    }
   ],
   "source": [
    "sets_counts = {\n",
    "    'train': 0,\n",
    "    'validation': 0\n",
    "}\n",
    "\n",
    "for set_name in sets:\n",
    "    for class_name in classes:\n",
    "        path = os.path.join(root_dir, set_name, class_name)\n",
    "        count = len(os.listdir(path))\n",
    "        print(path, 'has', count, 'images')\n",
    "        sets_counts[set_name] += count\n",
    "\n",
    "print(sets_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Script - Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.applications.mobilenet_v2.MobileNetV2(include_top = False,\n",
    "                                                      pooling = 'average',\n",
    "                                                      input_shape = (128, 128, 3)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "    model.layers[0].trainable = False\n",
    "    model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Script - Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a train.py\n",
    "def create_data_generators(root_dir, batch_size):\n",
    "    train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "        horizontal_flip = True,\n",
    "        zoom_range=[0.8,1.2],\n",
    "        rotation_range = 20\n",
    "    ).flow_from_directory(\n",
    "        os.path.join(root_dir, 'train')\n",
    "        target_size=(128,128),\n",
    "        batch_size = batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    val_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "\n",
    "    ).flow_from_directory(\n",
    "        os.path.join(root_dir, 'validation')\n",
    "        target_size=(128,128),\n",
    "        batch_size = batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    return train_data_generator, val_data_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Script - Putting it Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a train.py\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--epochs', type = int, default=3)\n",
    "    parser.add_argument('--batch_size', type=int, default=16)\n",
    "    parser.add_argument('--steps', type=int, default=int(np.ceil(train_gen.n / float(batch_size)))\n",
    "    parser.add_argument('--val_steps', type=int, default=int(np.ceil(val_gen.n / float(batch_size)))\n",
    "    \n",
    "    parser.add_argument('--model_dir', type=str)\n",
    "    parser.add_argument('--sm_model_dir', type=str, default = os.environ.get('SM_MODEL_DIR'))\n",
    "    \n",
    "    parser.add_argument('--train', type=str, default = os.environ.get('SM_CHANNEL_TRAINING'))\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    local_output_dur = args.sm_model_dir\n",
    "    local_root_dir = args.train\n",
    "    batch_size = args.batch_size\n",
    "    \n",
    "    model = create_model()\n",
    "    train_gen, val_gen = create_data_generators(local_root_dir, batch_size)\n",
    "    \n",
    "    _ = model.fit(\n",
    "        train_gen,\n",
    "        epochs=args.epochs,\n",
    "        steps_per_epoch=args.steps,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=args.val_steps\n",
    "    )\n",
    "    \n",
    "    model.save(os.path.join(local_output_dir, 'coursera_proj_model', '1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to S3\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket_name = \"swifty-datasets\"\n",
    "\n",
    "print(\"Uploading to S3\")\n",
    "s3_data_path = sess.upload_data(path=root_dir, bucket=bucket_name, key_prefix='coursera_tf_data')\n",
    "print(\"Uploaded to\", s3_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with TensorFlow Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "pets_estimator = TensorFlow(\n",
    "    entry_point='train.py',\n",
    "    role=role,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    instance_count=1,\n",
    "    py_version='py38',\n",
    "    framework_version = '2.6.0',\n",
    "    output_path='s3://swifty-ai-models/other_models/coursera_tf_sm/'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-07 18:36:21 Starting - Starting the training job...\n",
      "2022-04-07 18:36:50 Starting - Preparing the instances for trainingProfilerReport-1649356581: InProgress\n",
      ".........\n",
      "2022-04-07 18:38:13 Downloading - Downloading input data..."
     ]
    }
   ],
   "source": [
    "pets_estimator.fit(s3_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy TensorFlow Model\n",
    "We are going to create a new instance for inference. This takes time because a new instance has to be served."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_predictor = pets_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "print('\\nModel is deployed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dir = 'custom_data/validation/cat/'\n",
    "cat_images = [os.path.join(cat_dir, x) for x in os.listdir(cat_dir)]\n",
    "print(cat_images[0])\n",
    "\n",
    "dog_dir = 'custom_data/validation/dog/'\n",
    "dog_images = [os.path.join(dog_dir, x) for x in os.listdir(dog_dir)]\n",
    "print(dog_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(image_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    results = pets_predictor.predict(img)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = cat_images[0]\n",
    "results = get_pred(image_path)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = int(np.squeeze(results['predictions']) > 0.5)\n",
    "print('Predicted class_id:', class_id, 'with class_name:', classes[class_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Model Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(pets_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

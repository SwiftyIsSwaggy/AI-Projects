{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using AWS SageMaker for Inference\n",
    "On AWS sagemaker, using a pretrained Object Detection Model works best with tensorflow 2.8 and needs an updated version of sagemaker to use this version of tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.8/site-packages (from tensorflow_hub) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow_hub) (1.19.5)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.12.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sagemaker in /usr/local/lib/python3.8/site-packages (2.70.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.91.1.tar.gz (534 kB)\n",
      "     |████████████████████████████████| 534 kB 31.2 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting attrs==20.3.0\n",
      "  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: boto3>=1.20.21 in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.20.22)\n",
      "Requirement already satisfied: google-pasta in /usr/local/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.1 in /usr/local/lib/python3.8/site-packages (from sagemaker) (3.19.1)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /usr/local/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /usr/local/lib/python3.8/site-packages (from sagemaker) (4.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.2.5)\n",
      "Requirement already satisfied: pathos in /usr/local/lib/python3.8/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.22 in /usr/local/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker) (1.23.22)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (3.0.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/site-packages (from pandas->sagemaker) (2021.3)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: pox>=0.3.0 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.8/site-packages (from botocore<1.24.0,>=1.23.22->boto3>=1.20.21->sagemaker) (1.25.11)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.91.1-py2.py3-none-any.whl size=737694 sha256=71a1da6a1509d92fd87ecf1905789b5667ecf865457037af7740697977b41c5e\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/39/68/a7f8e2b484c8c9b492cc88d256ae7ef71de803467bc4c0801e\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: attrs, sagemaker\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.2.0\n",
      "    Uninstalling attrs-21.2.0:\n",
      "      Successfully uninstalled attrs-21.2.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.70.0\n",
      "    Uninstalling sagemaker-2.70.0:\n",
      "      Successfully uninstalled sagemaker-2.70.0\n",
      "Successfully installed attrs-20.3.0 sagemaker-2.91.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorflow==2.8\n",
      "  Using cached tensorflow-2.8.0-cp38-cp38-manylinux2010_x86_64.whl (497.6 MB)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
      "     |████████████████████████████████| 16.9 MB 20.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.42.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (0.10.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (59.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.6.3)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.1.2)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.26.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (3.19.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.1.0)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (3.7.4.3)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.12.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.25.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.1.1)\n",
      "Installing collected packages: numpy, tf-estimator-nightly, tensorflow-io-gcs-filesystem, tensorboard, libclang, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
      "    Found existing installation: tensorflow-io-gcs-filesystem 0.21.0\n",
      "    Uninstalling tensorflow-io-gcs-filesystem-0.21.0:\n",
      "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.21.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.6.0\n",
      "    Uninstalling tensorboard-2.6.0:\n",
      "      Successfully uninstalled tensorboard-2.6.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.6.2\n",
      "    Uninstalling tensorflow-2.6.2:\n",
      "      Successfully uninstalled tensorflow-2.6.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.8.0 which is incompatible.\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, but you have tensorflow-io-gcs-filesystem 0.26.0 which is incompatible.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.22.4 which is incompatible.\u001b[0m\n",
      "Successfully installed keras-2.8.0 libclang-14.0.1 numpy-1.22.4 tensorboard-2.8.0 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.26.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub\n",
    "%pip install -U sagemaker\n",
    "!pip install tensorflow==2.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import sagemaker\n",
    "import json\n",
    "import cv2\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: sagemaker-us-east-1-038469568353\n",
      "SageMaker ver: 2.91.1\n",
      "Tensorflow ver: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "dataset_bucket = \"swifty-datasets\"\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "print(\"Bucket: {}\".format(bucket))\n",
    "print(\"SageMaker ver: \" + sagemaker.__version__)\n",
    "print(\"Tensorflow ver: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "model = TensorFlowModel(model_data='s3://swifty-ai-models/other_models/object_detector.tar.gz', role=role,framework_version = '2.8')\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge', endpoint_name='object-detection-endpoint-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send the copy of the image arrat \n",
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  image = None\n",
    "  if(path.startswith('https')):\n",
    "    response = urlopen(path)\n",
    "    image_data = response.read()\n",
    "    image_data = BytesIO(image_data)\n",
    "    image = Image.open(image_data)\n",
    "  else:\n",
    "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(BytesIO(image_data)) \n",
    "    #resize and sent this image as array to endpoint for inference\n",
    "  basewidth = 128 #Resize to basewidth of 800 and resize it proportionally to the height\n",
    "  wpercent = (basewidth/float(image.size[0]))\n",
    "  hsize = int((float(image.size[1])*float(wpercent)))\n",
    "  image = image.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (1, im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = load_image_into_numpy_array(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send this to object detection model\n",
    "input_data = {\n",
    "  'instances': input_tensor.tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = json.dumps({\"instances\":input_tensor.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke API\n",
    "headers = {\"content-type\":\"application/json\"}\n",
    "json_response = requests.post('https://p5dv58hpub.execute-api.us-east-1.amazonaws.com/InitialStage/objectdataprediction',data=data,headers = headers)\n",
    "result = json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64.0, 72.0, 64.0, 86.0, 64.0, 1.0, 86.0, 84.0, 64.0, 88.0, 64.0, 64.0, 41.0, 64.0, 43.0, 65.0, 74.0, 88.0, 1.0, 1.0, 64.0, 19.0, 64.0, 1.0, 41.0, 16.0, 40.0, 16.0, 16.0, 64.0, 1.0, 1.0, 90.0, 86.0, 88.0, 16.0, 64.0, 74.0, 41.0, 62.0, 16.0, 38.0, 73.0, 33.0, 85.0, 87.0, 77.0, 82.0, 18.0, 1.0, 61.0, 64.0, 64.0, 16.0, 67.0, 41.0, 34.0, 84.0, 17.0, 52.0, 16.0, 18.0, 84.0, 85.0, 62.0, 63.0, 1.0, 84.0, 31.0, 86.0, 64.0, 28.0, 51.0, 16.0, 16.0, 64.0, 51.0, 16.0, 16.0, 84.0, 84.0, 16.0, 15.0, 50.0, 17.0, 64.0, 3.0, 87.0, 31.0, 64.0, 16.0, 86.0, 31.0, 62.0, 27.0, 17.0, 87.0, 1.0, 16.0, 51.0]\n",
      "[0.517624438, 0.454195559, 0.432849, 0.414067984, 0.409557164, 0.399034381, 0.390559494, 0.389045477, 0.347824693, 0.316123426, 0.305510849, 0.304259121, 0.303778112, 0.295902461, 0.291772664, 0.285102516, 0.275288075, 0.274885565, 0.2744039, 0.268493295, 0.261832327, 0.25850141, 0.252827942, 0.249252647, 0.248189956, 0.248147368, 0.240350157, 0.238704413, 0.236564338, 0.225014, 0.224780172, 0.22082445, 0.220649689, 0.218390316, 0.217139632, 0.216683775, 0.215868533, 0.213948727, 0.213318974, 0.211028904, 0.210105419, 0.207255244, 0.20441246, 0.202686667, 0.200385153, 0.199863613, 0.197628856, 0.197113425, 0.195220619, 0.192414403, 0.191368073, 0.191170186, 0.190691739, 0.189137906, 0.188491225, 0.18593055, 0.183947355, 0.18370083, 0.1835742, 0.18347466, 0.183363229, 0.18227753, 0.181589931, 0.181287646, 0.17978707, 0.178084165, 0.174599171, 0.174302071, 0.172837317, 0.17270112, 0.172571808, 0.172504187, 0.171954036, 0.170220315, 0.169410259, 0.169283688, 0.1690813, 0.169046491, 0.168575913, 0.168269336, 0.167570055, 0.167391717, 0.166905463, 0.165471315, 0.164879531, 0.162215859, 0.161524445, 0.161430061, 0.16123873, 0.159551382, 0.158688933, 0.157521516, 0.157208174, 0.157203257, 0.156866312, 0.155394793, 0.155250102, 0.154393911, 0.151926726, 0.150694877]\n"
     ]
    }
   ],
   "source": [
    "print(result['predictions'][0]['detection_classes'])\n",
    "print(result['predictions'][0]['detection_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_scores= result['predictions'][0]['detection_scores']\n",
    "detection_classes= result['predictions'][0]['detection_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16.0, 84.0, 86.0, 86.0, 64.0, 72.0, 16.0, 88.0, 16.0, 16.0, 5.0, 16.0, 65.0, 16.0, 84.0, 82.0, 16.0, 85.0, 1.0, 1.0, 16.0, 17.0, 64.0, 88.0, 16.0, 86.0, 19.0, 86.0, 38.0, 84.0, 16.0, 1.0, 16.0, 16.0, 51.0, 64.0, 16.0, 61.0, 16.0, 84.0, 16.0, 3.0, 16.0, 42.0, 16.0, 84.0, 50.0, 16.0, 51.0, 16.0, 48.0, 3.0, 16.0, 1.0, 44.0, 16.0, 24.0, 1.0, 16.0, 51.0, 16.0, 28.0, 88.0, 61.0, 84.0, 28.0, 34.0, 64.0, 48.0, 1.0, 62.0, 84.0, 73.0, 16.0, 64.0, 24.0, 1.0, 17.0, 5.0, 64.0, 16.0, 50.0, 85.0, 84.0, 16.0, 64.0, 86.0, 64.0, 67.0, 87.0, 43.0, 64.0, 1.0, 28.0, 16.0, 44.0, 16.0, 8.0, 84.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(result['predictions'][0]['detection_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):\n",
    "     \n",
    "    # insert the list to the set\n",
    "    list_set = set(list1)\n",
    "    # convert the set to the list\n",
    "    unique_list = (list(list_set))\n",
    "    print(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 3.0, 5.0, 8.0, 16.0, 17.0, 19.0, 24.0, 28.0, 34.0, 38.0, 42.0, 43.0, 44.0, 48.0, 50.0, 51.0, 61.0, 62.0, 64.0, 65.0, 67.0, 72.0, 73.0, 82.0, 84.0, 85.0, 86.0, 87.0, 88.0]\n"
     ]
    }
   ],
   "source": [
    "unique(result['predictions'][0]['detection_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len((result['predictions'][0]['detection_scores'])))\n",
    "print(len((result['predictions'][0]['detection_classes'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'street sign', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet', 'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'hair brush']\n"
     ]
    }
   ],
   "source": [
    "txt_file = open(\"cococlasses.txt\", \"r\")\n",
    "content = txt_file.read().split(\"\\n\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "print(len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird\n"
     ]
    }
   ],
   "source": [
    "print(content[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToInt(list1):\n",
    "    detected_classes=[]\n",
    "    for i in range(len(list1)):\n",
    "        detected_classes.append(int(list1[i]))\n",
    "    return detected_classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_classes = convertToInt(result['predictions'][0]['detection_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTop10Classes(list1, list2, content):\n",
    "    print(\"The system has detected the following objects:\")\n",
    "    print(\"Object \\t\\t\\t Confidence\")\n",
    "    for i in range(10):\n",
    "        print(content[list1[i]].capitalize(),\"\\t\\t\\t\",list2[i]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The system has detected the following objects:\n",
      "Object \t\t\t Confidence\n",
      "Bird \t\t\t 64.2007589\n",
      "Book \t\t\t 48.472\n",
      "Vase \t\t\t 46.1754799\n",
      "Vase \t\t\t 45.5887854\n",
      "Potted plant \t\t\t 44.4863498\n",
      "Tv \t\t\t 43.046379099999996\n",
      "Bird \t\t\t 40.3677404\n",
      "Teddy bear \t\t\t 39.5147175\n",
      "Bird \t\t\t 37.4859095\n",
      "Bird \t\t\t 35.2080941\n"
     ]
    }
   ],
   "source": [
    "findTop10Classes(detected_classes,detection_scores,content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete End Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without using AWS services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg'\n",
    "image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "plt.figure(figsize=(24,32))\n",
    "plt.imshow(image_np[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running inference\n",
    "results = detector(image_np)\n",
    " #needs tf 2.8 to work\n",
    "\n",
    "result = {key:value.numpy() for key,value in results.items()}\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['detection_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['detection_classes'])\n",
    "#Get image,\n",
    "#Predict and return output from end point\n",
    "#After predicting, Find way to add detection boxes to output and then save to AWS s3 on the image."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using AWS SageMaker for Inference\n",
    "On AWS sagemaker, using a pretrained Object Detection Model works best with tensorflow 2.8 and needs an updated version of sagemaker to use this version of tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow_hub) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.8/site-packages (from tensorflow_hub) (3.19.1)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.12.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sagemaker in /usr/local/lib/python3.8/site-packages (2.70.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.92.1.tar.gz (536 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting attrs==20.3.0\n",
      "  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.20.22)\n",
      "Requirement already satisfied: google-pasta in /usr/local/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.19.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /usr/local/lib/python3.8/site-packages (from sagemaker) (3.19.1)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /usr/local/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Collecting importlib-metadata<2.0,>=1.4.0\n",
      "  Using cached importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.2.5)\n",
      "Requirement already satisfied: pathos in /usr/local/lib/python3.8/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.22 in /usr/local/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.23.22)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata<2.0,>=1.4.0->sagemaker) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (3.0.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/site-packages (from pandas->sagemaker) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.8/site-packages (from botocore<1.24.0,>=1.23.22->boto3<2.0,>=1.20.21->sagemaker) (1.25.11)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.92.1-py2.py3-none-any.whl size=739509 sha256=cdd8338baa67ca2bd07dc39e3190acacfbeba309e1ced44eaa946d6ad1791be6\n",
      "  Stored in directory: /root/.cache/pip/wheels/1c/33/f6/8e5902410891d990c867bcf79b42282e6cebab5477d8d8f309\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: importlib-metadata, attrs, sagemaker\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.8.2\n",
      "    Uninstalling importlib-metadata-4.8.2:\n",
      "      Successfully uninstalled importlib-metadata-4.8.2\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.2.0\n",
      "    Uninstalling attrs-21.2.0:\n",
      "      Successfully uninstalled attrs-21.2.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.70.0\n",
      "    Uninstalling sagemaker-2.70.0:\n",
      "      Successfully uninstalled sagemaker-2.70.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 1.7.0 which is incompatible.\u001b[0m\n",
      "Successfully installed attrs-20.3.0 importlib-metadata-1.7.0 sagemaker-2.92.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorflow==2.8\n",
      "  Using cached tensorflow-2.8.0-cp38-cp38-manylinux2010_x86_64.whl (497.6 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (3.3.0)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (3.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (3.19.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.6.3)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.12.1)\n",
      "Collecting numpy>=1.20\n",
      "  Using cached numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (59.5.0)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (0.10.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (3.7.4.3)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.26.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (1.1.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.8/site-packages (from tensorflow==2.8) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.24.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.3.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.0)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.1.1)\n",
      "Installing collected packages: importlib-metadata, numpy, tf-estimator-nightly, tensorflow-io-gcs-filesystem, tensorboard, libclang, keras, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 1.7.0\n",
      "    Uninstalling importlib-metadata-1.7.0:\n",
      "      Successfully uninstalled importlib-metadata-1.7.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
      "    Found existing installation: tensorflow-io-gcs-filesystem 0.21.0\n",
      "    Uninstalling tensorflow-io-gcs-filesystem-0.21.0:\n",
      "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.21.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.6.0\n",
      "    Uninstalling tensorboard-2.6.0:\n",
      "      Successfully uninstalled tensorboard-2.6.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.6.0\n",
      "    Uninstalling keras-2.6.0:\n",
      "      Successfully uninstalled keras-2.6.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.6.2\n",
      "    Uninstalling tensorflow-2.6.2:\n",
      "      Successfully uninstalled tensorflow-2.6.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.8.0 which is incompatible.\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, but you have tensorflow-io-gcs-filesystem 0.26.0 which is incompatible.\n",
      "sagemaker 2.92.1 requires importlib-metadata<2.0,>=1.4.0, but you have importlib-metadata 4.11.4 which is incompatible.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.22.4 which is incompatible.\u001b[0m\n",
      "Successfully installed importlib-metadata-4.11.4 keras-2.8.0 libclang-14.0.1 numpy-1.22.4 tensorboard-2.8.0 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.26.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub\n",
    "%pip install -U sagemaker\n",
    "!pip install tensorflow==2.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import sagemaker\n",
    "import json\n",
    "import cv2\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: sagemaker-us-east-1-038469568353\n",
      "SageMaker ver: 2.92.1\n",
      "Tensorflow ver: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "dataset_bucket = \"swifty-datasets\"\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "print(\"Bucket: {}\".format(bucket))\n",
    "print(\"SageMaker ver: \" + sagemaker.__version__)\n",
    "print(\"Tensorflow ver: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateEndpointConfig operation: Cannot create already existing endpoint configuration \"arn:aws:sagemaker:us-east-1:038469568353:endpoint-config/object-detection-endpoint-1\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-40620af06ab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorFlowModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's3://swifty-ai-models/other_models/object_detector.tar.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframework_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2.8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ml.m5.xlarge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object-detection-endpoint-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/tensorflow/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, update_endpoint, async_inference_config, serverless_inference_config)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         return super(TensorFlowModel, self).deploy(\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, **kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0masync_inference_config_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masync_inference_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_request_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         self.sagemaker_session.endpoint_from_production_variants(\n\u001b[0m\u001b[1;32m   1113\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mproduction_variants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproduction_variant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict)\u001b[0m\n\u001b[1;32m   3610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3611\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating endpoint-config with name %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3612\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3614\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateEndpointConfig operation: Cannot create already existing endpoint configuration \"arn:aws:sagemaker:us-east-1:038469568353:endpoint-config/object-detection-endpoint-1\"."
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "model = TensorFlowModel(model_data='s3://swifty-ai-models/other_models/object_detector.tar.gz', role=role,framework_version = '2.8')\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge', endpoint_name='object-detection-endpoint-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send the copy of the image arrat \n",
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  image = None\n",
    "  if(path.startswith('https')):\n",
    "    response = urlopen(path)\n",
    "    image_data = response.read()\n",
    "    image_data = BytesIO(image_data)\n",
    "    image = Image.open(image_data)\n",
    "  else:\n",
    "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(BytesIO(image_data)) \n",
    "    #resize and sent this image as array to endpoint for inference\n",
    "  basewidth = 360 #Resize to basewidth of 800 and resize it proportionally to the height\n",
    "  wpercent = (basewidth/float(image.size[0]))\n",
    "  hsize = int((float(image.size[1])*float(wpercent)))\n",
    "  image = image.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (1, im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/AI-Projects/Fire_Detection\n"
     ]
    }
   ],
   "source": [
    "image_path = '/root/AI-Projects/Fire_Detection/FireScene.jpg' \n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = load_image_into_numpy_array(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send this to object detection model\n",
    "input_data = {\n",
    "  'instances': input_tensor.tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = json.dumps({\"instances\":input_tensor.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7f4a80c23370>>\n"
     ]
    }
   ],
   "source": [
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke API\n",
    "headers = {\"content-type\":\"application/json\"}\n",
    "json_response = requests.post('https://p5dv58hpub.execute-api.us-east-1.amazonaws.com/InitialStage/objectdataprediction',data=data,headers = headers)\n",
    "result = json.loads(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79.0, 79.0, 44.0, 51.0, 47.0, 51.0, 47.0, 79.0, 78.0, 47.0, 78.0, 78.0, 51.0, 81.0, 50.0, 81.0, 44.0, 86.0, 47.0, 86.0, 44.0, 81.0, 44.0, 82.0, 49.0, 44.0, 47.0, 78.0, 51.0, 82.0, 49.0, 81.0, 79.0, 85.0, 64.0, 82.0, 79.0, 50.0, 70.0, 86.0, 75.0, 80.0, 51.0, 44.0, 86.0, 85.0, 47.0, 79.0, 86.0, 81.0, 78.0, 44.0, 49.0, 50.0, 82.0, 78.0, 51.0, 80.0, 81.0, 50.0, 79.0, 44.0, 44.0, 75.0, 70.0, 51.0, 49.0, 82.0, 50.0, 44.0, 81.0, 51.0, 47.0, 79.0, 51.0, 84.0, 80.0, 82.0, 80.0, 50.0, 78.0, 51.0, 86.0, 47.0, 84.0, 51.0, 49.0, 1.0, 49.0, 90.0, 78.0, 50.0, 62.0, 86.0, 70.0, 64.0, 85.0, 81.0, 47.0, 82.0]\n",
      "[0.736179411, 0.514530957, 0.373843729, 0.354321957, 0.307223022, 0.30539915, 0.303582639, 0.297191262, 0.293246269, 0.289334387, 0.287522376, 0.284987092, 0.272672772, 0.269670308, 0.262967229, 0.261257708, 0.258633733, 0.258322507, 0.255708188, 0.255621731, 0.251642942, 0.2452856, 0.24437505, 0.241588891, 0.241532624, 0.241177261, 0.23638925, 0.236201406, 0.222489595, 0.208358705, 0.206984639, 0.206622154, 0.204856604, 0.204784393, 0.20089066, 0.198659301, 0.197631687, 0.195154667, 0.194543481, 0.194278538, 0.19414103, 0.19377616, 0.193585128, 0.192904174, 0.191415846, 0.190705717, 0.190622061, 0.190448254, 0.189869106, 0.189054221, 0.188720852, 0.187835157, 0.187636524, 0.186647773, 0.186579347, 0.184907466, 0.183973312, 0.182879746, 0.180908799, 0.180408657, 0.179325759, 0.178982526, 0.177061021, 0.17631954, 0.174884349, 0.172525495, 0.171617448, 0.17020601, 0.16914618, 0.16892767, 0.168700278, 0.167878091, 0.166797221, 0.165783435, 0.165448904, 0.165219784, 0.164886504, 0.163445711, 0.163032144, 0.1619533, 0.159849375, 0.158964336, 0.157918811, 0.157891661, 0.155064225, 0.154832661, 0.151196539, 0.150252134, 0.150138259, 0.148392826, 0.14715004, 0.146049082, 0.145267129, 0.144997358, 0.144525856, 0.144314945, 0.143866986, 0.143708944, 0.142161936, 0.141626269]\n"
     ]
    }
   ],
   "source": [
    "print(result['predictions'][0]['detection_classes'])\n",
    "print(result['predictions'][0]['detection_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_scores= result['predictions'][0]['detection_scores']\n",
    "detection_classes= result['predictions'][0]['detection_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79.0, 79.0, 44.0, 51.0, 47.0, 51.0, 47.0, 79.0, 78.0, 47.0, 78.0, 78.0, 51.0, 81.0, 50.0, 81.0, 44.0, 86.0, 47.0, 86.0, 44.0, 81.0, 44.0, 82.0, 49.0, 44.0, 47.0, 78.0, 51.0, 82.0, 49.0, 81.0, 79.0, 85.0, 64.0, 82.0, 79.0, 50.0, 70.0, 86.0, 75.0, 80.0, 51.0, 44.0, 86.0, 85.0, 47.0, 79.0, 86.0, 81.0, 78.0, 44.0, 49.0, 50.0, 82.0, 78.0, 51.0, 80.0, 81.0, 50.0, 79.0, 44.0, 44.0, 75.0, 70.0, 51.0, 49.0, 82.0, 50.0, 44.0, 81.0, 51.0, 47.0, 79.0, 51.0, 84.0, 80.0, 82.0, 80.0, 50.0, 78.0, 51.0, 86.0, 47.0, 84.0, 51.0, 49.0, 1.0, 49.0, 90.0, 78.0, 50.0, 62.0, 86.0, 70.0, 64.0, 85.0, 81.0, 47.0, 82.0]\n"
     ]
    }
   ],
   "source": [
    "print(result['predictions'][0]['detection_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):\n",
    "     \n",
    "    # insert the list to the set\n",
    "    list_set = set(list1)\n",
    "    # convert the set to the list\n",
    "    unique_list = (list(list_set))\n",
    "    print(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 44.0, 47.0, 49.0, 50.0, 51.0, 62.0, 64.0, 70.0, 75.0, 78.0, 79.0, 80.0, 81.0, 82.0, 84.0, 85.0, 86.0, 90.0]\n"
     ]
    }
   ],
   "source": [
    "unique(result['predictions'][0]['detection_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len((result['predictions'][0]['detection_scores'])))\n",
    "print(len((result['predictions'][0]['detection_classes'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'street sign', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet', 'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'hair brush']\n"
     ]
    }
   ],
   "source": [
    "txt_file = open(\"cococlasses.txt\", \"r\")\n",
    "content = txt_file.read().split(\"\\n\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "print(len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird\n"
     ]
    }
   ],
   "source": [
    "print(content[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI-Projects\n"
     ]
    }
   ],
   "source": [
    "!ls /root/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToInt(list1):\n",
    "    detected_classes=[]\n",
    "    for i in range(len(list1)):\n",
    "        detected_classes.append(int(list1[i]))\n",
    "    return detected_classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_classes = convertToInt(result['predictions'][0]['detection_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTop10Classes(list1, list2, content):\n",
    "    print(\"The system has detected the following objects:\")\n",
    "    print(\"Object \\t\\t\\t Confidence\")\n",
    "    for i in range(10):\n",
    "        print(content[list1[i]].capitalize(),\"\\t\\t\\t\",list2[i]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The system has detected the following objects:\n",
      "Object \t\t\t Confidence\n",
      "Oven \t\t\t 73.6179411\n",
      "Oven \t\t\t 51.4530957\n",
      "Bottle \t\t\t 37.3843729\n",
      "Bowl \t\t\t 35.4321957\n",
      "Cup \t\t\t 30.7223022\n",
      "Bowl \t\t\t 30.539915\n",
      "Cup \t\t\t 30.358263899999997\n",
      "Oven \t\t\t 29.7191262\n",
      "Microwave \t\t\t 29.324626900000002\n",
      "Cup \t\t\t 28.933438700000004\n"
     ]
    }
   ],
   "source": [
    "findTop10Classes(detected_classes,detection_scores,content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete End Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without using AWS services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg'\n",
    "image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "plt.figure(figsize=(24,32))\n",
    "plt.imshow(image_np[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running inference\n",
    "results = detector(image_np)\n",
    " #needs tf 2.8 to work\n",
    "\n",
    "result = {key:value.numpy() for key,value in results.items()}\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['detection_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['detection_classes'])\n",
    "#Get image,\n",
    "#Predict and return output from end point\n",
    "#After predicting, Find way to add detection boxes to output and then save to AWS s3 on the image."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

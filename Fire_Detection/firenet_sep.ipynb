{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC9lCieIWihi"
      },
      "source": [
        "# The Fire Net Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Depthwise Separable Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnC7eRBOWihr"
      },
      "source": [
        "This is my own model using depthwise separable convolutions. There is a version which has been designed before using normal standard convolution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or97TIE-Wihs"
      },
      "source": [
        "Therefore, for my project we have:\n",
        "* A bench mark model which is a pre trained Mobile net.\n",
        "* A fire net model made up of standard convolution.\n",
        "* A fire net model made up of depthwise convolution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7C4n7KqWihu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import shutil\n",
        "import tensorboard\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1KEXI9EWihx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization, DepthwiseConv2D, AveragePooling2D\n",
        "from sklearn.metrics import classification_report, confusion_matrix,roc_curve,auc, roc_auc_score,precision_recall_curve\n",
        "from sklearn.metrics import PrecisionRecallDisplay,RocCurveDisplay,ConfusionMatrixDisplay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUgCTbwdWihy",
        "outputId": "abb2846e-9fcf-4c0c-ef12-d1c0f9c65652"
      },
      "outputs": [],
      "source": [
        "_URL = 'https://fire-net-datasets.s3.amazonaws.com/Training_Dataset.zip'\n",
        "\n",
        "zip_file = tf.keras.utils.get_file(origin=_URL,extract=True)  \n",
        "#This will ge the file and extract it to a directory and extract to /Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfZqTHq0Wih0",
        "outputId": "4ab8347a-868e-42ba-e90d-7745550ba202"
      },
      "outputs": [],
      "source": [
        "print(os.path.dirname(zip_file))\n",
        "#This function returns the directory of the extracted folder without the extracted folder inclusive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBqfaImMWih1",
        "outputId": "83ad734e-b79e-4422-de78-523c051c2ef1"
      },
      "outputs": [],
      "source": [
        "base_dir = os.path.join(os.path.dirname(zip_file), 'Training Dataset')\n",
        "#A good way to add the directory of the extracted folder and also the extracted folder itself.\n",
        "print(base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LOG_DIR = os.path.join(os.getcwd(), \"Fire_Detection/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT2yDuO5Wih2"
      },
      "outputs": [],
      "source": [
        "classes = ['Fire', 'NoFire']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq5L8VBkWih3",
        "outputId": "36993da4-3a31-40fa-8d01-52ac05cec118"
      },
      "outputs": [],
      "source": [
        "for cl in classes:\n",
        "  img_path = os.path.join(base_dir, cl)\n",
        "  images = glob.glob(img_path + '/*.jpg')\n",
        "  print(\"{}: {} Images\".format(cl, len(images)))\n",
        "  train, val = images[:round(len(images)*0.7)], images[round(len(images)*0.7):]\n",
        "\n",
        "  for t in train:\n",
        "    if not os.path.exists(os.path.join(base_dir, 'train', cl)):\n",
        "      os.makedirs(os.path.join(base_dir, 'train', cl))\n",
        "    shutil.move(t, os.path.join(base_dir, 'train', cl))\n",
        "\n",
        "  for v in val:\n",
        "    if not os.path.exists(os.path.join(base_dir, 'val', cl)):\n",
        "      os.makedirs(os.path.join(base_dir, 'val', cl))\n",
        "    shutil.move(v, os.path.join(base_dir, 'val', cl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDeD3hWmWih4"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzuW49yMWih4"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "IMG_SHAPE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCf8XG3EWih5",
        "outputId": "6675bc09-f8fe-4612-d475-50200c835efd"
      },
      "outputs": [],
      "source": [
        "image_gen_train = ImageDataGenerator(rescale = 1./255,\n",
        "                    zoom_range = 0.5,\n",
        "                    rotation_range=45,\n",
        "                    horizontal_flip=True,\n",
        "                    width_shift_range=0.15,\n",
        "                    height_shift_range=0.15,\n",
        "                    shear_range=0.2)\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                            directory=train_dir,\n",
        "                                            shuffle=True,\n",
        "                                            target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                            class_mode='binary')\n",
        "print(train_data_gen.samples)\n",
        "print(train_data_gen.n)\n",
        "train_data_num = train_data_gen.samples\n",
        "#Find our size of datasets. each"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uMVRSYsWih7"
      },
      "outputs": [],
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "4IkRmnvpWih8",
        "outputId": "04672084-8339-431c-b32c-53b4ba7381b3"
      },
      "outputs": [],
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0hVUkckWih9",
        "outputId": "0eccddec-c612-4850-edd8-3f3e0d6e9a2d"
      },
      "outputs": [],
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                            directory=val_dir,\n",
        "                            target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                            class_mode='binary',\n",
        "                            shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQbM3f74Wih_",
        "outputId": "7469d2d3-669c-46e4-d44f-4711f749cf24"
      },
      "outputs": [],
      "source": [
        "print(val_data_gen.samples)\n",
        "print(val_data_gen.n)\n",
        "val_data_num = val_data_gen.samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAdAe9brWih_"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32,kernel_size = 3, padding = \"same\", input_shape = (IMG_SHAPE, IMG_SHAPE, 3)), strides = 2)\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =1, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =1, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 256, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =1, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 256, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "#Four round blocks, MobileNet has five instead\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =1, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =1, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =1, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =1, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 512, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#After 4 blocks\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 1024, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(DepthwiseConv2D(kernel_size = 3, strides =2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 1024, kernel_size = 1, padding = \"same\", strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(AveragePooling2D(7,7), strides=(1,1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anEEIooXWiiA"
      },
      "source": [
        "### Places to Test\n",
        "1. Overfit first so that you see maximum number of epoch. (Overfits above 60)\n",
        "2. After overfitting, find the epoch where you want to reduce the learning rate. (This is 60 epoch)\n",
        "3. Test with discarding dropout and use batch normalization. (Performance Accuracy) **Test this\n",
        "4. Add a Dense layer of 128. (Accuracy) //No need, parameters already high.\n",
        "5. MaxPooling to default stride (Accuracy) //Will increase computation.\n",
        "6. After finding best epoch, use reduce early and stop. (Generalization)// No need, found the optimum range at about 60 epoch.\n",
        "7. Convert to depthwise separable convolution and increase layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CLmkg1bWiiB",
        "outputId": "e4a6715e-ed30-445a-afe1-a5c5e97dcd38"
      },
      "outputs": [],
      "source": [
        "model.summary()\n",
        "\n",
        "#Mobile Net had 2 million parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSg7-6_IWiiC",
        "outputId": "5c696acc-f42b-4388-b36e-11c63123639e"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "model.compile(optimizer=\"adam\",\n",
        "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs= EPOCHS,\n",
        "                steps_per_epoch = int(np.ceil(train_data_gen.n / float(batch_size))),\n",
        "                validation_data = val_data_gen,\n",
        "                validation_steps = int(np.ceil(val_data_gen.n / float(batch_size))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "PnoEjqPPWiiD",
        "outputId": "ac812921-2ff0-4d33-bfd0-8f751ca6f745"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Run this on AWS \n",
        "EFS_PATH_LOG_DIR = \"/\".join(LOG_DIR.strip(\"/\").split('/')[1:-1])\n",
        "print (EFS_PATH_LOG_DIR)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Run this command in the terminal\n",
        "\n",
        "pip install tensorboard\n",
        "tensorboard --logdir <EFS_PATH_LOG_DIR>\n",
        "\n",
        "To launch TensorBoard, copy your Studio URL and replace lab? with proxy/6006/ as follows. You must include the trailing / character.\n",
        "\n",
        "https://<YOUR_URL>.studio.region.sagemaker.aws/jupyter/default/proxy/6006/\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Run this on Colab or other places\n",
        "\n",
        "#Can run this before training to view the logs before training occurs or run after training to view after training\n",
        "!tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrdHcomxWiiE",
        "outputId": "429170e1-5653-4355-bf2b-296f406f90a4"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix and Classification Report\n",
        "val_data_gen.reset()\n",
        "Y_pred = model.predict(val_data_gen, int(np.ceil(val_data_gen.n / float(batch_size))))\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(val_data_gen.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['Fire', 'No Fire']\n",
        "print(classification_report(val_data_gen.classes, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kanGMfrOvcoR",
        "outputId": "32112600-b6d6-449f-edd1-33699188aae0"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix and Classification Report\n",
        "\n",
        "#Something is Wrong\n",
        "val_data_gen.reset()\n",
        "Y_pred = model.predict(val_data_gen, int(np.ceil(val_data_gen.n / float(batch_size))))\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(val_data_gen.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['Fire', 'No Fire']\n",
        "print(classification_report(val_data_gen.classes, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "jQiVGIbzvcoS",
        "outputId": "7b6f1c5b-79af-431d-8252-ebd147b1b72e"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(val_data_gen.classes, y_pred)\n",
        "\n",
        "cm_display = ConfusionMatrixDisplay(cm).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "f5ybGLPXvcoS",
        "outputId": "9d1820a2-185c-4534-954a-5bd2b567c6e9"
      },
      "outputs": [],
      "source": [
        "fpr_keras, tpr_keras, thresholds_keras = roc_curve(val_data_gen.classes, y_pred)\n",
        "auc_keras = auc(fpr_keras, tpr_keras)\n",
        "\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "yshW_CvpvcoS",
        "outputId": "12486209-1491-4e6c-a42e-3155252f20d0"
      },
      "outputs": [],
      "source": [
        "prec, recall, _ = precision_recall_curve(val_data_gen.classes, y_pred)\n",
        "pr_display = PrecisionRecallDisplay(precision=prec, recall=recall).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFKZf9XIAuxH"
      },
      "outputs": [],
      "source": [
        "model_name = \"firenet\"\n",
        "model_fullname = \"{}_epochs_{}\".format(model_name,EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAsOGeU6APir",
        "outputId": "f65d851c-fe6c-476c-ca73-43b90927acc3"
      },
      "outputs": [],
      "source": [
        "export_path_keras = \"./{}.h5\".format(model_fullname)\n",
        "print(export_path_keras)\n",
        "\n",
        "model.save(export_path_keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-lsrLU9BxyA",
        "outputId": "8358f6ea-f086-42b4-8abc-653a66fd03d5"
      },
      "outputs": [],
      "source": [
        "export_path_sm = \"./{}\".format(model_fullname)\n",
        "print(export_path_sm)\n",
        "\n",
        "tf.saved_model.save(model, export_path_sm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBwrXfQoCHN5",
        "outputId": "09b6a552-a38c-4ff8-d17e-3d4b60daea80"
      },
      "outputs": [],
      "source": [
        "!ls {export_path_sm}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pILbHQcHCP5p",
        "outputId": "3e3c8439-62ef-478f-9c8e-2f1ee6886c79"
      },
      "outputs": [],
      "source": [
        "!zip -r {model_fullname}.zip {export_path_sm}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VMbCXWs8CTad",
        "outputId": "bc8322b9-5cf6-457f-cab9-236bac0cb1e5"
      },
      "outputs": [],
      "source": [
        "#Download saved model to Disk\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('./{}.zip'.format(model_fullname)\n",
        "except ImportError:\n",
        "  pass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "firenet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

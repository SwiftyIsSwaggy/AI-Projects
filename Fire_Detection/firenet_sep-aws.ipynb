{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SC9lCieIWihi"
   },
   "source": [
    "# The Fire Net Model trained on AWS SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Depthwise Separable Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnC7eRBOWihr"
   },
   "source": [
    "This is my own model using depthwise separable convolutions. There is a version which has been designed before using normal standard convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Or97TIE-Wihs"
   },
   "source": [
    "Therefore, for my project we have:\n",
    "* A bench mark model which is a pre trained Mobile net.\n",
    "* A fire net model made up of standard convolution.\n",
    "* A fire net model made up of depthwise convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /usr/local/lib/python3.8/site-packages (2.70.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.92.0.tar.gz (536 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting attrs==20.3.0\n",
      "  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: boto3>=1.20.21 in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.20.22)\n",
      "Requirement already satisfied: google-pasta in /usr/local/lib/python3.8/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.1 in /usr/local/lib/python3.8/site-packages (from sagemaker) (3.19.1)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /usr/local/lib/python3.8/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /usr/local/lib/python3.8/site-packages (from sagemaker) (4.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (from sagemaker) (1.2.5)\n",
      "Requirement already satisfied: pathos in /usr/local/lib/python3.8/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.22 in /usr/local/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker) (1.23.22)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging>=20.0->sagemaker) (3.0.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/site-packages (from pandas->sagemaker) (2021.3)\n",
      "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /usr/local/lib/python3.8/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.8/site-packages (from botocore<1.24.0,>=1.23.22->boto3>=1.20.21->sagemaker) (1.25.11)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.92.0-py2.py3-none-any.whl size=739501 sha256=bb8f83c62475bcb3db33aa4c8f284ae98cbf96c86ff6d05e79f2482483e4e1b2\n",
      "  Stored in directory: /root/.cache/pip/wheels/58/69/5f/ba693a644851ec2b36f0255ac43fc945f77bbf9494ee2ac692\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: attrs, sagemaker\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.2.0\n",
      "    Uninstalling attrs-21.2.0:\n",
      "      Successfully uninstalled attrs-21.2.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.70.0\n",
      "    Uninstalling sagemaker-2.70.0:\n",
      "      Successfully uninstalled sagemaker-2.70.0\n",
      "Successfully installed attrs-20.3.0 sagemaker-2.92.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "k7C4n7KqWihu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import shutil\n",
    "import tensorboard\n",
    "import datetime\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P1KEXI9EWihx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization, DepthwiseConv2D, AveragePooling2D\n",
    "from sklearn.metrics import classification_report, confusion_matrix,roc_curve,auc, roc_auc_score,precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay,RocCurveDisplay,ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUgCTbwdWihy",
    "outputId": "abb2846e-9fcf-4c0c-ef12-d1c0f9c65652"
   },
   "outputs": [],
   "source": [
    "#initial download to instance. After downloading to S3, no need to run this again.\n",
    "_URL = 'https://swifty-datasets.s3.amazonaws.com/firenet_data/test/'\n",
    "\n",
    "zip_file = tf.keras.utils.get_file(origin=_URL,extract=True)  \n",
    "#This will ge the file and extract it to a directory and extract to /Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfZqTHq0Wih0",
    "outputId": "4ab8347a-868e-42ba-e90d-7745550ba202"
   },
   "outputs": [],
   "source": [
    "print(os.path.dirname(zip_file))\n",
    "#This function returns the directory of the extracted folder without the extracted folder inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBqfaImMWih1",
    "outputId": "83ad734e-b79e-4422-de78-523c051c2ef1"
   },
   "outputs": [],
   "source": [
    "#No need to run this after uploading to S3\n",
    "base_dir = os.path.join(os.path.dirname(zip_file), 'Training Dataset')\n",
    "#A good way to add the directory of the extracted folder and also the extracted folder itself.\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sT2yDuO5Wih2"
   },
   "outputs": [],
   "source": [
    "classes = ['Fire', 'NoFire']\n",
    "sets = ['train', 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yq5L8VBkWih3",
    "outputId": "36993da4-3a31-40fa-8d01-52ac05cec118"
   },
   "outputs": [],
   "source": [
    "for cl in classes:\n",
    "  img_path = os.path.join(base_dir, cl)\n",
    "  images = glob.glob(img_path + '/*')\n",
    "  print(\"{}: {} Images\".format(cl, len(images)))\n",
    "  train, val = images[:round(len(images)*0.7)], images[round(len(images)*0.7):]\n",
    "\n",
    "  for t in train:\n",
    "    if not os.path.exists(os.path.join(base_dir, 'train', cl)):\n",
    "      os.makedirs(os.path.join(base_dir, 'train', cl))\n",
    "    shutil.move(t, os.path.join(base_dir, 'train', cl))\n",
    "\n",
    "  for v in val:\n",
    "    if not os.path.exists(os.path.join(base_dir, 'val', cl)):\n",
    "      os.makedirs(os.path.join(base_dir, 'val', cl))\n",
    "    shutil.move(v, os.path.join(base_dir, 'val', cl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDeD3hWmWih4"
   },
   "outputs": [],
   "source": [
    "sets_counts = {\n",
    "    'train': 0,\n",
    "    'val': 0\n",
    "}\n",
    "\n",
    "for set_name in sets:\n",
    "    for class_name in classes:\n",
    "        path = os.path.join(base_dir, set_name, class_name)\n",
    "        count = len(os.listdir(path))\n",
    "        print(path, 'has', count, 'images')\n",
    "        sets_counts[set_name] += count\n",
    "\n",
    "print(sets_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FzuW49yMWih4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: sagemaker-us-east-1-038469568353\n",
      "SageMaker ver: 2.86.2\n",
      "Tensorflow ver: 2.6.2\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "dataset_bucket = \"swifty-datasets\"\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"firenet_aws\"\n",
    "tensorflow_logs_path = \"s3://{}/{}/logs\".format(bucket, prefix)\n",
    "\n",
    "print(\"Bucket: {}\".format(bucket))\n",
    "print(\"SageMaker ver: \" + sagemaker.__version__)\n",
    "print(\"Tensorflow ver: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not run this when data already in S3\n",
    "print(\"Uploading to S3\")\n",
    "s3_data_path = sess.upload_data(path=base_dir, bucket=dataset_bucket, key_prefix='firenet_data')\n",
    "print(\"Uploaded to\", s3_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead make it this:\n",
    "s3_data_path = \"s3://swifty-datasets/firenet_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_metric_definition = [\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \".*loss: ([0-9\\\\.]+) - accuracy: [0-9\\\\.]+.*\"},\n",
    "    {\"Name\": \"train:accuracy\", \"Regex\": \".*loss: [0-9\\\\.]+ - accuracy: ([0-9\\\\.]+).*\"},\n",
    "    {\n",
    "        \"Name\": \"validation:accuracy\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: ([0-9\\\\.]+).*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"validation:loss\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: ([0-9\\\\.]+) - val_accuracy: [0-9\\\\.]+.*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"sec/steps\",\n",
    "        \"Regex\": \".* (\\d+)[mu]s/step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: [0-9\\\\.]+\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4uMVRSYsWih7"
   },
   "outputs": [],
   "source": [
    "shared_hyper_parameters = {\"epochs\": 80, \"tf-logs-path\": tensorflow_logs_path, \"learning-rate\": 0.001, \"batch_size\":64}\n",
    "#ml.g4dn.xlarge GPU at 0.96 per hour\n",
    "estimator = TensorFlow(\n",
    "    entry_point='train.py',\n",
    "    base_job_name=\"firenet-training-80ep-deltalr-b64\",\n",
    "    source_dir=\"source_dir\",\n",
    "    role=role,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=1,\n",
    "    py_version='py38',\n",
    "    framework_version = '2.6.2',\n",
    "    hyperparameters =shared_hyper_parameters,\n",
    "    metric_definitions=keras_metric_definition,\n",
    "    output_path='s3://swifty-ai-models/other_models/firenet_tf_sm'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "4IkRmnvpWih8",
    "outputId": "04672084-8339-431c-b32c-53b4ba7381b3"
   },
   "outputs": [],
   "source": [
    "estimator.fit(s3_data_path, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0hVUkckWih9",
    "outputId": "0eccddec-c612-4850-edd8-3f3e0d6e9a2d"
   },
   "outputs": [],
   "source": [
    "fire_predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "print('\\nModel is deployed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQbM3f74Wih_",
    "outputId": "7469d2d3-669c-46e4-d44f-4711f749cf24"
   },
   "outputs": [],
   "source": [
    "#Upload images to the test directory first.\n",
    "test_dir = 'Fire_Detection/data/test/'\n",
    "test_images = [os.path.join(test_dir, x) for x in os.listdir(test_dir)]\n",
    "print(test_images[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAdAe9brWih_"
   },
   "outputs": [],
   "source": [
    "def get_pred(img_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(128, 128))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    results = fire_predictor.predict(img)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5CLmkg1bWiiB",
    "outputId": "e4a6715e-ed30-445a-afe1-a5c5e97dcd38"
   },
   "outputs": [],
   "source": [
    "#Getting predictions for all images\n",
    "def showPredictions(image_list):\n",
    "    predicted_classes = []\n",
    "    for i in range(len(image_list)):\n",
    "        image_path = image_list[i]\n",
    "        results = get_pred(image_path)\n",
    "        print(results)\n",
    "        predicted_id = np.argmax(results)\n",
    "        predicted_class = classes[predicted_id]\n",
    "        predicted_classes.append(predicted_class)\n",
    "    plt.figure(figsize=(10,9))\n",
    "    for n in range(len(image_list)):\n",
    "        plt.subplot(6,5,n+1)\n",
    "        plt.subplots_adjust(hspace = 0.3)\n",
    "        image = plt.imread(image_list[n])\n",
    "        plt.imshow(image)\n",
    "        plt.title(predicted_classes[n].title())\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSg7-6_IWiiC",
    "outputId": "5c696acc-f42b-4388-b36e-11c63123639e"
   },
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(fire_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just run this in the new terminal\n",
    "## First install sagemaker\n",
    "``pip install sagemaker``\n",
    "## Install Tensorboard\n",
    "``pip install tensorboard`` \n",
    "## Next line then run the following command\n",
    "``tensorboard --logdir s3://sagemaker-us-east-1-038469568353/firenet_aws/logs ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://d-aten2bwlosyw.studio.us-east-1.sagemaker.aws/proxy/6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "        if epoch < 10:\n",
    "            return 0.001\n",
    "        elif epoch < 30:\n",
    "            return 0.0005\n",
    "        elif epoch < 50:\n",
    "            return 0.00025\n",
    "        elif epoch < 60:\n",
    "            return 0.0001\n",
    "        else:\n",
    "            return 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir s3://sagemaker-us-east-1-038469568353/firenet_aws/logs\n"
     ]
    }
   ],
   "source": [
    "aws_region = sess.boto_region_name\n",
    "!AWS_REGION={aws_region}\n",
    "!echo tensorboard --logdir {tensorflow_logs_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"learning-rate\": ContinuousParameter(0.00001, 0.001),\n",
    "    \"batch_size\": CategoricalParameter([64, 128]),\n",
    "    \"optimizer\": CategoricalParameter([\"sgd\", \"adam\", \"rmsprop\"]),\n",
    "}\n",
    "\n",
    "objective_metric_name = \"validation:accuracy\"\n",
    "\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions=keras_metric_definition,\n",
    "    objective_type=\"Maximize\",\n",
    "    max_jobs=6,\n",
    "    max_parallel_jobs=2,\n",
    "    early_stopping_type=\"Auto\",\n",
    "    base_tuning_job_name=\"firenet-hpo-tuning\",\n",
    ")\n",
    "\n",
    "tuner.fit(s3_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have got the best model, we can deploy it to an endpoint. Please refer to other SageMaker sample notebooks or SageMaker documentation to see how to deploy a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this before launching tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste the command that is the output of the next cell to start your tensorboard instance on Studio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_region = sess.boto_region_name\n",
    "!AWS_REGION={aws_region}\n",
    "!echo tensorboard --logdir {tensorflow_logs_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance of TensorBoard will be available at https://<notebook instance hostname>/proxy/6006/. By default TensorBoard assigns port 6006, but if itâ€™s already in use TensorBoard will increase the port by 1, so 6007, 6008 and so on until it finds an available port."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link to tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://d-aten2bwlosyw.studio.us-east-1.sagemaker.aws/jupyter/default/proxy/6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard --logdir s3://sagemaker-us-east-1-038469568353/firenet_aws/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(os.getcwd(), \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFS_PATH_LOG_DIR = \"/\".join(LOG_DIR.strip(\"/\").split('/')[1:-1])\n",
    "print (EFS_PATH_LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "firenet.ipynb",
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "a25b2d42e0fe57251b6ece2b75d30429fe26895efea1faac6949f166a7477be7"
  },
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

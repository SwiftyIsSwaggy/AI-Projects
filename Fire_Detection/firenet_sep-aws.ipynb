{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SC9lCieIWihi"
   },
   "source": [
    "# The Fire Net Model trained on AWS SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Depthwise Separable Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnC7eRBOWihr"
   },
   "source": [
    "This is my own model using depthwise separable convolutions. There is a version which has been designed before using normal standard convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Or97TIE-Wihs"
   },
   "source": [
    "Therefore, for my project we have:\n",
    "* A bench mark model which is a pre trained Mobile net.\n",
    "* A fire net model made up of standard convolution.\n",
    "* A fire net model made up of depthwise convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "k7C4n7KqWihu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import shutil\n",
    "import tensorboard\n",
    "import datetime\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P1KEXI9EWihx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization, DepthwiseConv2D, AveragePooling2D\n",
    "from sklearn.metrics import classification_report, confusion_matrix,roc_curve,auc, roc_auc_score,precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay,RocCurveDisplay,ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUgCTbwdWihy",
    "outputId": "abb2846e-9fcf-4c0c-ef12-d1c0f9c65652"
   },
   "outputs": [],
   "source": [
    "#initial download to instance. After downloading to S3, no need to run this again.\n",
    "_URL = 'https://fire-net-datasets.s3.amazonaws.com/Training_Dataset.zip'\n",
    "\n",
    "zip_file = tf.keras.utils.get_file(origin=_URL,extract=True)  \n",
    "#This will ge the file and extract it to a directory and extract to /Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfZqTHq0Wih0",
    "outputId": "4ab8347a-868e-42ba-e90d-7745550ba202"
   },
   "outputs": [],
   "source": [
    "print(os.path.dirname(zip_file))\n",
    "#This function returns the directory of the extracted folder without the extracted folder inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBqfaImMWih1",
    "outputId": "83ad734e-b79e-4422-de78-523c051c2ef1"
   },
   "outputs": [],
   "source": [
    "#No need to run this after uploading to S3\n",
    "base_dir = os.path.join(os.path.dirname(zip_file), 'Training Dataset')\n",
    "#A good way to add the directory of the extracted folder and also the extracted folder itself.\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sT2yDuO5Wih2"
   },
   "outputs": [],
   "source": [
    "classes = ['Fire', 'NoFire']\n",
    "sets = ['train', 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yq5L8VBkWih3",
    "outputId": "36993da4-3a31-40fa-8d01-52ac05cec118"
   },
   "outputs": [],
   "source": [
    "for cl in classes:\n",
    "  img_path = os.path.join(base_dir, cl)\n",
    "  images = glob.glob(img_path + '/*')\n",
    "  print(\"{}: {} Images\".format(cl, len(images)))\n",
    "  train, val = images[:round(len(images)*0.7)], images[round(len(images)*0.7):]\n",
    "\n",
    "  for t in train:\n",
    "    if not os.path.exists(os.path.join(base_dir, 'train', cl)):\n",
    "      os.makedirs(os.path.join(base_dir, 'train', cl))\n",
    "    shutil.move(t, os.path.join(base_dir, 'train', cl))\n",
    "\n",
    "  for v in val:\n",
    "    if not os.path.exists(os.path.join(base_dir, 'val', cl)):\n",
    "      os.makedirs(os.path.join(base_dir, 'val', cl))\n",
    "    shutil.move(v, os.path.join(base_dir, 'val', cl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDeD3hWmWih4"
   },
   "outputs": [],
   "source": [
    "sets_counts = {\n",
    "    'train': 0,\n",
    "    'val': 0\n",
    "}\n",
    "\n",
    "for set_name in sets:\n",
    "    for class_name in classes:\n",
    "        path = os.path.join(base_dir, set_name, class_name)\n",
    "        count = len(os.listdir(path))\n",
    "        print(path, 'has', count, 'images')\n",
    "        sets_counts[set_name] += count\n",
    "\n",
    "print(sets_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FzuW49yMWih4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: sagemaker-us-east-1-038469568353\n",
      "SageMaker ver: 2.86.0\n",
      "Tensorflow ver: 2.6.2\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "dataset_bucket = \"swifty-datasets\"\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"firenet_aws\"\n",
    "tensorflow_logs_path = \"s3://{}/{}/logs\".format(bucket, prefix)\n",
    "\n",
    "print(\"Bucket: {}\".format(bucket))\n",
    "print(\"SageMaker ver: \" + sagemaker.__version__)\n",
    "print(\"Tensorflow ver: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not run this when data already in S3\n",
    "print(\"Uploading to S3\")\n",
    "s3_data_path = sess.upload_data(path=base_dir, bucket=dataset_bucket, key_prefix='firenet_data')\n",
    "print(\"Uploaded to\", s3_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead make it this:\n",
    "s3_data_path = \"s3://swifty-datasets/firenet_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_metric_definition = [\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \".*loss: ([0-9\\\\.]+) - accuracy: [0-9\\\\.]+.*\"},\n",
    "    {\"Name\": \"train:accuracy\", \"Regex\": \".*loss: [0-9\\\\.]+ - accuracy: ([0-9\\\\.]+).*\"},\n",
    "    {\n",
    "        \"Name\": \"validation:accuracy\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: ([0-9\\\\.]+).*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"validation:loss\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: ([0-9\\\\.]+) - val_accuracy: [0-9\\\\.]+.*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"sec/steps\",\n",
    "        \"Regex\": \".* (\\d+)[mu]s/step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: [0-9\\\\.]+\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4uMVRSYsWih7"
   },
   "outputs": [],
   "source": [
    "shared_hyper_parameters = {\"epochs\": 100, \"tf-logs-path\": tensorflow_logs_path}\n",
    "#ml.g4dn.xlarge GPU at 0.96 per hour\n",
    "estimator = TensorFlow(\n",
    "    entry_point='train.py',\n",
    "    base_job_name=\"firenet-training-hpo\",\n",
    "    source_dir=\"source_dir\",\n",
    "    role=role,\n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    instance_count=1,\n",
    "    py_version='py38',\n",
    "    framework_version = '2.6.2',\n",
    "    hyperparameters =shared_hyper_parameters,\n",
    "    metric_definitions=keras_metric_definition,\n",
    "    output_path='s3://swifty-ai-models/other_models/firenet_tf_sm'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "4IkRmnvpWih8",
    "outputId": "04672084-8339-431c-b32c-53b4ba7381b3"
   },
   "outputs": [],
   "source": [
    "estimator.fit(s3_data_path, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0hVUkckWih9",
    "outputId": "0eccddec-c612-4850-edd8-3f3e0d6e9a2d"
   },
   "outputs": [],
   "source": [
    "fire_predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "print('\\nModel is deployed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQbM3f74Wih_",
    "outputId": "7469d2d3-669c-46e4-d44f-4711f749cf24"
   },
   "outputs": [],
   "source": [
    "#Upload images to the test directory first.\n",
    "test_dir = 'Fire_Detection/data/test/'\n",
    "test_images = [os.path.join(test_dir, x) for x in os.listdir(test_dir)]\n",
    "print(test_images[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAdAe9brWih_"
   },
   "outputs": [],
   "source": [
    "def get_pred(img_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(128, 128))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    results = fire_predictor.predict(img)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5CLmkg1bWiiB",
    "outputId": "e4a6715e-ed30-445a-afe1-a5c5e97dcd38"
   },
   "outputs": [],
   "source": [
    "#Getting predictions for all images\n",
    "def showPredictions(image_list):\n",
    "    predicted_classes = []\n",
    "    for i in range(len(image_list)):\n",
    "        image_path = image_list[i]\n",
    "        results = get_pred(image_path)\n",
    "        print(results)\n",
    "        predicted_id = np.argmax(results)\n",
    "        predicted_class = classes[predicted_id]\n",
    "        predicted_classes.append(predicted_class)\n",
    "    plt.figure(figsize=(10,9))\n",
    "    for n in range(len(image_list)):\n",
    "        plt.subplot(6,5,n+1)\n",
    "        plt.subplots_adjust(hspace = 0.3)\n",
    "        image = plt.imread(image_list[n])\n",
    "        plt.imshow(image)\n",
    "        plt.title(predicted_classes[n].title())\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSg7-6_IWiiC",
    "outputId": "5c696acc-f42b-4388-b36e-11c63123639e"
   },
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(fire_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir s3://sagemaker-us-east-1-038469568353/firenet_aws/logs\n"
     ]
    }
   ],
   "source": [
    "aws_region = sess.boto_region_name\n",
    "!AWS_REGION={aws_region}\n",
    "!echo tensorboard --logdir {tensorflow_logs_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"learning-rate\": ContinuousParameter(0.00001, 0.001),\n",
    "    \"batch_size\": CategoricalParameter([64, 128]),\n",
    "    \"optimizer\": CategoricalParameter([\"sgd\", \"adam\", \"rmsprop\"]),\n",
    "}\n",
    "\n",
    "objective_metric_name = \"validation:accuracy\"\n",
    "\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions=keras_metric_definition,\n",
    "    objective_type=\"Maximize\",\n",
    "    max_jobs=6,\n",
    "    max_parallel_jobs=2,\n",
    "    early_stopping_type=\"Auto\",\n",
    "    base_tuning_job_name=\"firenet-hpo-tuning\",\n",
    ")\n",
    "\n",
    "tuner.fit(s3_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have got the best model, we can deploy it to an endpoint. Please refer to other SageMaker sample notebooks or SageMaker documentation to see how to deploy a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste the command that is the output of the next cell to start your tensorboard instance on Studio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_region = sess.boto_region_name\n",
    "!AWS_REGION={aws_region}\n",
    "!echo tensorboard --logdir {tensorflow_logs_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance of TensorBoard will be available at https://<notebook instance hostname>/proxy/6006/. By default TensorBoard assigns port 6006, but if it’s already in use TensorBoard will increase the port by 1, so 6007, 6008 and so on until it finds an available port."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link to tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://d-aten2bwlosyw.studio.us-east-1.sagemaker.aws/jupyter/default/proxy/6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "firenet.ipynb",
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-gpu-py38-cu112-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
